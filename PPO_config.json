{
    "action_repeat": 1,
    "batch_size": 2048,
    "discounting": 0.97,
    "entropy_cost": 0.001,
    "episode_length": 1000,
    "learning_rate": 0.0003,
    "normalize_observations": true,
    "num_envs": 2048,
    "num_evals": 100,
    "num_minibatches": 32,
    "num_timesteps": 1000000000,
    "num_updates_per_batch": 4,
    "reward_scaling": 1.0,
    "unroll_length": 20,
    "max_grad_norm": 0.5
}